{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d0a3aec-837c-41f8-bda3-2cc3d01b5685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from category_encoders import BinaryEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from datetime import datetime\n",
    "import pgeocode\n",
    "import cupy as cp\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c540014-a7e8-4c4f-ac37-d85e6ad48a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4272/3946057250.py:1: DtypeWarning: Columns (16,134) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('real_estate_raw.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('real_estate_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9798302-e823-4e1e-850a-2aa35ed01a05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'original_list_price',\n",
    "    'list_price',\n",
    "    'close_price',\n",
    "    'association_fee',\n",
    "    'tax_annual_amount',\n",
    "    'days_on_market',\n",
    "    'cumulative_days_on_market',\n",
    "    'previous_list_price',\n",
    "    'living_area',\n",
    "    'lot_size_acres',\n",
    "\n",
    "    'rooms_total',\n",
    "    'bedrooms_total',\n",
    "    'bathrooms_full',\n",
    "    'bathrooms_half',\n",
    "    'garage_spaces',\n",
    " \n",
    "    'year_built',\n",
    "    \n",
    "    'postal_code',\n",
    "\n",
    "    'elementary_school_district',\n",
    "    'middle_or_junior_school_district',\n",
    "    'high_school_district',\n",
    "    \n",
    "    'accessibility_features',\n",
    "    'heating',\n",
    "    'water_source',\n",
    "    'sewer',\n",
    "    'lot_features',\n",
    "    'roof',\n",
    "    'community_features',\n",
    "    'laundry_features',\n",
    "    'cooling',\n",
    "    'association_fee_includes',\n",
    "    'mrd_din',\n",
    "    'mrd_ext',\n",
    "    'mrd_fireplace_location',\n",
    "    'ownership',\n",
    "    'mrd_bas',\n",
    "    'mrd_pkn',\n",
    "    \n",
    "    'waterfront_yn',\n",
    "    'mrd_disability_access',\n",
    "    'mrd_garage_onsite',\n",
    "    'new_construction_yn',\n",
    "        \n",
    "    'mrd_rehab_year',\n",
    "        \n",
    "    'mrd_tnu',\n",
    "    'mrd_tpc',\n",
    "    'mrd_tpe'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dba63438-ff3f-4f3a-b31a-74cd7d53bd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82ed4cae-2423-40fc-b159-19b2fe68b020",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400918 entries, 0 to 400917\n",
      "Data columns (total 44 columns):\n",
      " #   Column                            Non-Null Count   Dtype  \n",
      "---  ------                            --------------   -----  \n",
      " 0   original_list_price               400918 non-null  float64\n",
      " 1   list_price                        400918 non-null  float64\n",
      " 2   close_price                       400918 non-null  float64\n",
      " 3   association_fee                   400918 non-null  float64\n",
      " 4   tax_annual_amount                 400918 non-null  float64\n",
      " 5   days_on_market                    400918 non-null  int64  \n",
      " 6   cumulative_days_on_market         400918 non-null  int64  \n",
      " 7   previous_list_price               400918 non-null  int64  \n",
      " 8   living_area                       400918 non-null  float64\n",
      " 9   lot_size_acres                    400918 non-null  float64\n",
      " 10  rooms_total                       400918 non-null  int64  \n",
      " 11  bedrooms_total                    400918 non-null  int64  \n",
      " 12  bathrooms_full                    400918 non-null  int64  \n",
      " 13  bathrooms_half                    400918 non-null  int64  \n",
      " 14  garage_spaces                     400918 non-null  float64\n",
      " 15  year_built                        400918 non-null  int64  \n",
      " 16  postal_code                       400918 non-null  object \n",
      " 17  elementary_school_district        398787 non-null  object \n",
      " 18  middle_or_junior_school_district  398752 non-null  object \n",
      " 19  high_school_district              398663 non-null  object \n",
      " 20  accessibility_features            14070 non-null   object \n",
      " 21  heating                           400767 non-null  object \n",
      " 22  water_source                      399106 non-null  object \n",
      " 23  sewer                             389725 non-null  object \n",
      " 24  lot_features                      171248 non-null  object \n",
      " 25  roof                              222012 non-null  object \n",
      " 26  community_features                127103 non-null  object \n",
      " 27  laundry_features                  183093 non-null  object \n",
      " 28  cooling                           399929 non-null  object \n",
      " 29  association_fee_includes          386781 non-null  object \n",
      " 30  mrd_din                           244672 non-null  object \n",
      " 31  mrd_ext                           399960 non-null  object \n",
      " 32  mrd_fireplace_location            159381 non-null  object \n",
      " 33  ownership                         387064 non-null  object \n",
      " 34  mrd_bas                           287976 non-null  object \n",
      " 35  mrd_pkn                           382084 non-null  object \n",
      " 36  waterfront_yn                     400918 non-null  bool   \n",
      " 37  mrd_disability_access             386728 non-null  object \n",
      " 38  mrd_garage_onsite                 330279 non-null  object \n",
      " 39  new_construction_yn               400918 non-null  bool   \n",
      " 40  mrd_rehab_year                    75236 non-null   float64\n",
      " 41  mrd_tnu                           134511 non-null  float64\n",
      " 42  mrd_tpc                           134747 non-null  object \n",
      " 43  mrd_tpe                           265920 non-null  object \n",
      "dtypes: bool(2), float64(10), int64(8), object(24)\n",
      "memory usage: 129.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info(verbose=True,show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "15da22d4-368e-4b9d-b405-cfa92086546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocess:\n",
    "    def __init__(self):\n",
    "        self.all_schools_dict = {}\n",
    "        self.ohe_encoder_dict = {}\n",
    "        self.school_binarizer = {}\n",
    "        self.feature_binarizer = {}\n",
    "        self.numeric_value_normalizer = None\n",
    "        self.numeric_target_normalizer = None\n",
    "        self.feature_list =['accessibility_features',\n",
    "                                'heating',\n",
    "                                'water_source',\n",
    "                                'sewer',\n",
    "                                'lot_features',\n",
    "                                'roof',\n",
    "                                'community_features',\n",
    "                                'laundry_features',\n",
    "                                'cooling',\n",
    "                                'association_fee_includes',\n",
    "                                'mrd_din',\n",
    "                                'mrd_ext',\n",
    "                                'mrd_fireplace_location',\n",
    "                                'ownership',\n",
    "                                'mrd_bas',\n",
    "                                'mrd_pkn',\n",
    "                                'mrd_tpc',\n",
    "                                'mrd_tpe']\n",
    "        self.school_features = ['elementary_school_district','middle_or_junior_school_district','high_school_district']\n",
    "        self.room_features = ['rooms_total','bedrooms_total','bathrooms_full','bathrooms_half','garage_spaces']\n",
    "        self.all_multi_binarized_features = []\n",
    "        self.all_postal_binarized_features = []\n",
    "        self.all_boolean_features = []\n",
    "        self.all_continuous_features = ['original_list_price',\n",
    "                                        'list_price',\n",
    "                                        'association_fee',\n",
    "                                        'tax_annual_amount',\n",
    "                                        'days_on_market',\n",
    "                                        'cumulative_days_on_market',\n",
    "                                        'previous_list_price',\n",
    "                                        'living_area',\n",
    "                                        'lot_size_acres']\n",
    "        \n",
    "\n",
    "    def clean_schools(self, df, dataset='train', schools=None):\n",
    "        ## find missing school districts by zip code ##\n",
    "        if schools is None:\n",
    "            schools = self.school_features\n",
    "        \n",
    "        if dataset == 'train':\n",
    "            before = df.elementary_school_district.isna().sum(),df.middle_or_junior_school_district.isna().sum(),df.high_school_district.isna().sum()\n",
    "            \n",
    "            for dist in schools:\n",
    "                df[dist] = df[dist].apply(lambda x: str(x).lower() if pd.notnull(x) else x)\n",
    "                \n",
    "            for dist in schools:\n",
    "                df_school = df[['postal_code',dist]].copy()\n",
    "                df_school = df_school.dropna(subset=[dist],how='all')\n",
    "                \n",
    "                df_school = df_school.groupby([\"postal_code\",dist]).size().reset_index().rename(columns={0:'count'})\n",
    "                school_dict = dict(zip(df_school.postal_code, df_school[dist]))\n",
    "                self.all_schools_dict[dist] = school_dict\n",
    "            \n",
    "                df[dist] = df[dist].fillna(df.postal_code.map(school_dict))\n",
    "            \n",
    "            after = df.elementary_school_district.isna().sum(),df.middle_or_junior_school_district.isna().sum(),df.high_school_district.isna().sum()\n",
    "            print(f'Reduced district nulls from {before} to {after} after.')\n",
    "            df[schools] = df[schools].fillna(0)\n",
    "            \n",
    "        elif dataset == 'predict':\n",
    "            before = df.elementary_school_district.isna().sum(),df.middle_or_junior_school_district.isna().sum(),df.high_school_district.isna().sum()\n",
    "            for dist in schools:\n",
    "                df[dist] = df[dist].apply(lambda x: str(x).lower() if pd.notnull(x) else x)\n",
    "                \n",
    "            for dist in schools:\n",
    "                school_dict = self.all_schools_dict[dist]\n",
    "                df[dist] = df[dist].fillna(df.postal_code.map(school_dict))\n",
    "\n",
    "            after = df.elementary_school_district.isna().sum(),df.middle_or_junior_school_district.isna().sum(),df.high_school_district.isna().sum()\n",
    "            print(f'Reduced district nulls from {before} to {after} after.') \n",
    "            \n",
    "            df[schools] = df[schools].fillna(0)\n",
    "\n",
    "        return df\n",
    "            \n",
    "    def binarize_schools(self, df, dataset='train', schools=None):   \n",
    "        ## binarize school districts transform ##\n",
    "        if schools is None:\n",
    "            schools = self.school_features\n",
    "\n",
    "        binarized_features = []\n",
    "        \n",
    "        if dataset == 'train':\n",
    "            \n",
    "            for dist in schools:\n",
    "                df_dist = df[dist].copy()\n",
    "                encoder = BinaryEncoder(cols=[dist])\n",
    "                df_binarize = encoder.fit_transform(df_dist)\n",
    "                df = pd.concat([df,df_binarize],axis=1)\n",
    "                df = df.drop(dist,axis=1)\n",
    "                binarized_features.extend(encoder.feature_names_out_)\n",
    "                self.school_binarizer[dist] = encoder\n",
    "                \n",
    "        elif dataset == 'predict':\n",
    "            \n",
    "            for dist in schools:\n",
    "                df_dist = df[dist].copy()\n",
    "                df_binarize = self.school_binarizer[dist].transform(df_dist)\n",
    "                df = pd.concat([df,df_binarize],axis=1)\n",
    "                df = df.drop(dist,axis=1)\n",
    "\n",
    "        self.all_postal_binarized_features.extend(binarized_features)\n",
    "        df[binarized_features] = df[binarized_features].astype('bool')\n",
    "        \n",
    "        return df \n",
    "\n",
    "    def clean_age(self, df):\n",
    "        ## building age transform ##\n",
    "        current_year = datetime.now().year\n",
    "        \n",
    "        df['age'] = df['year_built'].apply(lambda x: current_year-int(x) if int(x) > 0 else x)\n",
    "        bins = [-1, 0, 10, 20, 30, 40, 50, 60, 70, 80, 1000]\n",
    "        labels = ['0','1-10', '10-20', '20-30', '30-40', '40-50', '50-60', '60-70', '70-80', '80+']\n",
    "        df['age_label'] = pd.cut(df.age, bins=bins, labels=labels)\n",
    "        df = df.drop('age',axis=1)\n",
    "\n",
    "        df[\"age_label\"] = df[\"age_label\"].astype(\"category\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def clean_booleans(self, df):\n",
    "        ## boolean fields transform ##\n",
    "        df['waterfront_yn'] = df['waterfront_yn'].fillna(False)\n",
    "        df['new_construction_yn'] = df['new_construction_yn'].fillna(False)\n",
    "        df['mrd_disability_access'] = df['mrd_disability_access'].fillna('No')\n",
    "        df['mrd_disability_access'] = pd.Series(np.where(df.mrd_disability_access.values == 'Yes', True, False), df.index)\n",
    "        df['mrd_garage_onsite'] = df['mrd_garage_onsite'].fillna('No')\n",
    "        df['mrd_garage_onsite'] = pd.Series(np.where(df.mrd_garage_onsite.values == 'Yes', True, False), df.index)\n",
    "        df['mrd_rehab_year'] = df['mrd_rehab_year'].apply(lambda x: True if pd.notnull(x) else False)\n",
    "\n",
    "        boolean = ['waterfront_yn','new_construction_yn','mrd_disability_access','mrd_garage_onsite','mrd_rehab_year']\n",
    "        df[boolean] = df[boolean].astype('bool')\n",
    "\n",
    "        return df\n",
    "\n",
    "    def clean_room_features(self, df, room_list=None):\n",
    "        ## rooms binning transform ##\n",
    "        if room_list is None:\n",
    "            room_list = self.room_features\n",
    "        \n",
    "        for feature in room_list:\n",
    "            min_val = -1\n",
    "            zero_val = 0\n",
    "            first_quant = 1\n",
    "            second_quant = 2\n",
    "            third_quant = 3\n",
    "            last_quant = 4\n",
    "            extra_quant = 5\n",
    "            max_val = 1000\n",
    "            bins = [min_val,zero_val,first_quant,second_quant,third_quant,last_quant,extra_quant,max_val]\n",
    "            labels = [f'{zero_val}',f'{first_quant}',f'{second_quant}',f'{third_quant}',f'{last_quant}',f'{extra_quant}',f'{extra_quant}+']\n",
    "            df[feature] = pd.cut(df[feature], bins=bins, labels=labels, duplicates='drop')\n",
    "\n",
    "        df[room_list] = df[room_list].astype('category')\n",
    "            \n",
    "        return df\n",
    "\n",
    "    def clean_postal_codes(self, df):\n",
    "        ## postal code to long lat coordinates ##\n",
    "        geolocator = pgeocode.Nominatim('US')\n",
    "        geocode_dict = {}\n",
    "        for postal_code in list(df.postal_code.unique()):\n",
    "            location = geolocator.query_postal_code(str(postal_code))\n",
    "            geocode_dict[postal_code] = (location.longitude,location.latitude)\n",
    "        \n",
    "        df['postal_long'] = df['postal_code'].apply(lambda x: geocode_dict[x][0] if ((pd.notnull(x)) and (x in geocode_dict)) else np.nan)\n",
    "        df['postal_lat'] = df['postal_code'].apply(lambda x: geocode_dict[x][1] if ((pd.notnull(x)) and (x in geocode_dict)) else np.nan)\n",
    "        \n",
    "        df.postal_long = df.postal_long.fillna(0)\n",
    "        df.postal_lat = df.postal_lat.fillna(0)\n",
    "\n",
    "        df[['postal_long','postal_lat']] = df[['postal_long','postal_lat']].astype('float32')\n",
    "        add_list = ['postal_long','postal_lat']\n",
    "        for el in add_list:\n",
    "            if el not in self.all_continuous_features:\n",
    "                self.all_continuous_features.extend(['postal_long','postal_lat'])\n",
    "\n",
    "        return df\n",
    "\n",
    "    def clean_multi_label_features(self, df, feature_list=None):\n",
    "        ## splitting of features into individual lists per cell for labelizer ##\n",
    "        if feature_list is None:\n",
    "            feature_list = self.feature_list\n",
    "            \n",
    "        for feature in feature_list:\n",
    "            df[feature] = df[feature].fillna(f'None_{feature}')\n",
    "            curr_len=(len(df[feature].str.split(',\\s*').explode().unique().tolist()))\n",
    "            print(f'{feature} has {curr_len} unique categories.')\n",
    "            df[feature] = df[feature].str.replace('[{}\"]','',regex=True).str.split(',\\s*')\n",
    "\n",
    "        return df\n",
    "\n",
    "    def multi_label_binarizer(self, df, dataset='train', feature_list=None):\n",
    "        \n",
    "        if feature_list is None:\n",
    "            feature_list = self.feature_list\n",
    "\n",
    "        if dataset == 'train':\n",
    "            for feature in feature_list:\n",
    "                mlb = MultiLabelBinarizer()\n",
    "                df = df.join(\n",
    "                        pd.DataFrame(\n",
    "                                mlb.fit_transform(df.pop(feature)),\n",
    "                                index=df.index,\n",
    "                                columns=mlb.classes_), lsuffix=f'{feature}_')\n",
    "                self.feature_binarizer[feature] = mlb\n",
    "                self.all_multi_binarized_features.extend(list(mlb.classes_))\n",
    "                \n",
    "        elif dataset == 'predict':\n",
    "            for feature in feature_list:\n",
    "                mlb = self.feature_binarizer[feature]\n",
    "                df = df.join(\n",
    "                        pd.DataFrame(\n",
    "                                mlb.transform(df.pop(feature)),\n",
    "                                index=df.index,\n",
    "                                columns=mlb.classes_), lsuffix=f'{feature}_')\n",
    "\n",
    "        \n",
    "\n",
    "        for col in self.all_multi_binarized_features:\n",
    "            df[col] = df[col].astype('bool')\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def normalize_numeric(self, df, dataset='train', numerical = None):\n",
    "        ## taking numeric continous features and normalizing them using a min max scaler ##\n",
    "        if numerical is None:\n",
    "            numerical = self.all_continuous_features\n",
    "            \n",
    "        if dataset == 'train':\n",
    "            print(df[numerical].columns)\n",
    "            scaler = MinMaxScaler()\n",
    "            df[numerical] = scaler.fit_transform(df[numerical])\n",
    "            self.numeric_value_normalizer = scaler\n",
    "            \n",
    "        elif dataset == 'predict':\n",
    "            print(df[numerical].columns)\n",
    "            scaler = self.numeric_value_normalizer\n",
    "            df[numerical] = scaler.transform(df[numerical])\n",
    "\n",
    "        df[numerical] = df[numerical].astype('float32')\n",
    "            \n",
    "        return df\n",
    "\n",
    "    def normalize_target(self, df, dataset='train',target=None):\n",
    "        ## taking the target feature and normalizing it using a min max scaler ##\n",
    "        if target is None:\n",
    "            target = 'close_price'\n",
    "            \n",
    "        if dataset == 'train':\n",
    "            target_scaler = MinMaxScaler()\n",
    "            df[target] = target_scaler.fit_transform(df[target].to_numpy().reshape(-1, 1))\n",
    "            self.numeric_target_normalizer = target_scaler\n",
    "        elif dataset == 'predict':\n",
    "            target_scaler = self.numeric_target_normalizer\n",
    "            df[target] = target_scaler.transform(df[target].to_numpy().reshape(-1, 1))\n",
    "\n",
    "        df[target] = df[target].astype('float32')\n",
    "\n",
    "        return df\n",
    "\n",
    "    def ohe_categories(self, df, dataset='train', categorical=None):\n",
    "\n",
    "        if categorical is None:\n",
    "            categorical = list(df.select_dtypes(include=['category']).columns)\n",
    "    \n",
    "        if dataset == 'train':\n",
    "        \n",
    "            for cat in categorical:\n",
    "                df_ohe = df[cat].values.reshape(-1, 1)\n",
    "                enc = OneHotEncoder(handle_unknown = \"ignore\").fit(df_ohe)\n",
    "                df_ohe = enc.transform(df_ohe).toarray()\n",
    "                df_ohe = pd.DataFrame(df_ohe, columns=enc.categories_)\n",
    "                df_ohe = df_ohe.add_prefix(f'{cat}_')\n",
    "                self.all_boolean_features.extend(list(df_ohe.columns))\n",
    "                df = pd.concat([df,df_ohe], axis=1)\n",
    "                df = df.drop(cat,axis=1)\n",
    "                self.ohe_encoder_dict[cat] = enc\n",
    "\n",
    "        elif dataset == 'predict':\n",
    "        \n",
    "            for cat in categorical:\n",
    "                df_ohe = df[cat].values.reshape(-1, 1)\n",
    "                enc = self.ohe_encoder_dict[cat]\n",
    "                df_ohe = enc.transform(df_ohe).toarray()\n",
    "                df_ohe = pd.DataFrame(df_ohe, columns=enc.categories_)\n",
    "                df_ohe = df_ohe.add_prefix(f'{cat}_')\n",
    "                df = pd.concat([df,df_ohe], axis=1)\n",
    "                df = df.drop(cat,axis=1)\n",
    "                self.ohe_encoder_dict['cat'] = enc\n",
    "\n",
    "        for col in self.all_boolean_features:\n",
    "            df[col] = df[col].astype('bool')\n",
    "        \n",
    "        return df\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "71853013-69a4-4003-ae2e-ec8c283240d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['close_price']]\n",
    "X = df.drop('close_price',axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ef4bd33-0a00-4e25-8dae-07dc06552190",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced district nulls from (1428, 1451, 1514) to (476, 488, 481) after.\n",
      "accessibility_features has 222 unique categories.\n",
      "heating has 83 unique categories.\n",
      "water_source has 26 unique categories.\n",
      "sewer has 28 unique categories.\n",
      "lot_features has 211 unique categories.\n",
      "roof has 33 unique categories.\n",
      "community_features has 66 unique categories.\n",
      "laundry_features has 45 unique categories.\n",
      "cooling has 57 unique categories.\n",
      "association_fee_includes has 85 unique categories.\n",
      "mrd_din has 7 unique categories.\n",
      "mrd_ext has 35 unique categories.\n",
      "mrd_fireplace_location has 16 unique categories.\n",
      "ownership has 6 unique categories.\n",
      "mrd_bas has 25 unique categories.\n",
      "mrd_pkn has 4 unique categories.\n",
      "mrd_tpc has 30 unique categories.\n",
      "mrd_tpe has 18 unique categories.\n",
      "Index(['original_list_price', 'list_price', 'association_fee',\n",
      "       'tax_annual_amount', 'days_on_market', 'cumulative_days_on_market',\n",
      "       'previous_list_price', 'living_area', 'lot_size_acres', 'postal_long',\n",
      "       'postal_lat'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "dp = DataPreprocess()\n",
    "\n",
    "def preprocess_train(df):\n",
    "    df = dp.clean_schools(df,dataset='train')\n",
    "    df = dp.binarize_schools(df,dataset='train')\n",
    "    df = dp.clean_age(df)\n",
    "    df = dp.clean_booleans(df)\n",
    "    df = dp.clean_room_features(df)\n",
    "    df = dp.clean_postal_codes(df)\n",
    "    df = dp.clean_multi_label_features(df)\n",
    "    df = dp.multi_label_binarizer(df,dataset='train')\n",
    "    df = dp.normalize_numeric(df,dataset='train')\n",
    "    df = dp.ohe_categories(df,dataset='train')\n",
    "    return df\n",
    "X_train = preprocess_train(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d7bd2a5-af3d-4ebb-9e12-5492057d5720",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess_target_train(df):\n",
    "    df = dp.normalize_target(df,dataset='train')\n",
    "    return df\n",
    "    \n",
    "y_train = preprocess_target_train(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "805641f4-6a70-4294-9b0e-51d61783da53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   close_price\n",
       "0     0.007833\n",
       "1     0.003194\n",
       "2     0.002083\n",
       "3     0.010072\n",
       "4     0.005000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "00841bf8-86ab-446e-9536-36fb966b0962",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced district nulls from (703, 715, 741) to (247, 250, 258) after.\n",
      "accessibility_features has 208 unique categories.\n",
      "heating has 82 unique categories.\n",
      "water_source has 26 unique categories.\n",
      "sewer has 27 unique categories.\n",
      "lot_features has 211 unique categories.\n",
      "roof has 31 unique categories.\n",
      "community_features has 65 unique categories.\n",
      "laundry_features has 45 unique categories.\n",
      "cooling has 52 unique categories.\n",
      "association_fee_includes has 84 unique categories.\n",
      "mrd_din has 7 unique categories.\n",
      "mrd_ext has 34 unique categories.\n",
      "mrd_fireplace_location has 16 unique categories.\n",
      "ownership has 6 unique categories.\n",
      "mrd_bas has 25 unique categories.\n",
      "mrd_pkn has 4 unique categories.\n",
      "mrd_tpc has 30 unique categories.\n",
      "mrd_tpe has 18 unique categories.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charon/.local/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:900: UserWarning: unknown class(es) ['Coal'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['original_list_price', 'list_price', 'association_fee',\n",
      "       'tax_annual_amount', 'days_on_market', 'cumulative_days_on_market',\n",
      "       'previous_list_price', 'living_area', 'lot_size_acres', 'postal_long',\n",
      "       'postal_lat'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def preprocess_test(df):\n",
    "    df = dp.clean_schools(df,dataset='predict')\n",
    "    df = dp.binarize_schools(df,dataset='predict')\n",
    "    df = dp.clean_age(df)\n",
    "    df = dp.clean_booleans(df)\n",
    "    df = dp.clean_room_features(df)\n",
    "    df = dp.clean_postal_codes(df)\n",
    "    df = dp.clean_multi_label_features(df)\n",
    "    df = dp.multi_label_binarizer(df,dataset='predict')\n",
    "    df = dp.normalize_numeric(df,dataset='predict')\n",
    "    df = dp.ohe_categories(df,dataset='predict')\n",
    "    return df\n",
    "\n",
    "X_test = preprocess_test(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ddfae2aa-f098-49bd-b20e-aa98a48af584",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess_target_test(df):\n",
    "    df = dp.normalize_target(df,dataset='predict')\n",
    "    return df\n",
    "    \n",
    "y_test = preprocess_target_test(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b8439ee6-2151-4e20-b1d6-60a7c3b44a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['postal_code'],axis=1)\n",
    "X_test = X_test.drop(['postal_code'],axis=1)\n",
    "\n",
    "X_train.mrd_tnu = X_train.mrd_tnu.fillna(0)\n",
    "X_test.mrd_tnu = X_test.mrd_tnu.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cdac0473-03b3-41cb-bb10-ae4965273276",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\n",
    "# from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n",
    "\n",
    "# #xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\", n_estimators=80,learning_rate=0.11669835581158701, max_depth=6, subsample=0.6628468243767216)\n",
    "# xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\", n_estimators=80)\n",
    "\n",
    "# # X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# xgb_model.fit(X_train, y_train, eval_set=[(X_test, y_test)])\n",
    "\n",
    "# y_pred = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "95ccdeb4-2e9d-4c42-98b0-1bae42b24fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put data into GPU\n",
    "X_train_cp = cp.array(X_train.to_numpy().astype('float32'))\n",
    "X_test_cp = cp.array(X_test.to_numpy().astype('float32'))\n",
    "y_train_cp = cp.array(y_train.to_numpy().astype('float32'))\n",
    "y_test_cp = cp.array(y_test.to_numpy().astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ef6ac41d-6b7f-4ac5-ae98-832a695bc275",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████| 100/100 [02:21<00:00,  1.42s/trial, best loss: 4.5959554881847e-06]\n",
      "Best set of hyperparameters:  {'learning_rate': 0.10678426900942385, 'max_depth': 11, 'max_leaves': 0, 'n_estimators': 59, 'subsample': 0.7031297379916002}\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK\n",
    "\n",
    "# Define the hyperparameter space\n",
    "space = {\n",
    "    # 'max_depth': hp.quniform('max_depth', 2, 8, 1),\n",
    "    'n_estimators': hp.choice('n_estimators', np.arange(10, 120, dtype=int)),\n",
    "    'max_depth': hp.choice('max_depth', np.arange(1, 14, dtype=int)),\n",
    "    'max_leaves': hp.choice('max_leaves', np.arange(0, 6, dtype=int)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -5, -2),\n",
    "    'subsample': hp.uniform('subsample', 0.25, 1)\n",
    "}\n",
    "\n",
    "# Define the objective function to minimize\n",
    "def objective(params):\n",
    "    xgb_model = xgb.XGBRegressor(device = 'cuda',objective=\"reg:squarederror\", **params)\n",
    "    # xgb_model = xgb.XGBClassifier(**params)\n",
    "    xgb_model.fit(X_train_cp, y_train_cp)\n",
    "    y_pred = xgb_model.predict(X_test_cp)\n",
    "    score = mean_squared_error(y_test_cp.get(), y_pred)\n",
    "    return {'loss': score, 'status': STATUS_OK}\n",
    "\n",
    "# Perform the optimization\n",
    "best_params = fmin(objective, space, algo=tpe.suggest, max_evals=100)\n",
    "print(\"Best set of hyperparameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bfb62947-d7f4-467e-9c5d-244c8aa50b5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.00836\n",
      "[1]\tvalidation_0-rmse:0.00755\n",
      "[2]\tvalidation_0-rmse:0.00685\n",
      "[3]\tvalidation_0-rmse:0.00622\n",
      "[4]\tvalidation_0-rmse:0.00567\n",
      "[5]\tvalidation_0-rmse:0.00518\n",
      "[6]\tvalidation_0-rmse:0.00475\n",
      "[7]\tvalidation_0-rmse:0.00438\n",
      "[8]\tvalidation_0-rmse:0.00406\n",
      "[9]\tvalidation_0-rmse:0.00378\n",
      "[10]\tvalidation_0-rmse:0.00354\n",
      "[11]\tvalidation_0-rmse:0.00334\n",
      "[12]\tvalidation_0-rmse:0.00316\n",
      "[13]\tvalidation_0-rmse:0.00301\n",
      "[14]\tvalidation_0-rmse:0.00288\n",
      "[15]\tvalidation_0-rmse:0.00278\n",
      "[16]\tvalidation_0-rmse:0.00268\n",
      "[17]\tvalidation_0-rmse:0.00258\n",
      "[18]\tvalidation_0-rmse:0.00252\n",
      "[19]\tvalidation_0-rmse:0.00246\n",
      "[20]\tvalidation_0-rmse:0.00242\n",
      "[21]\tvalidation_0-rmse:0.00238\n",
      "[22]\tvalidation_0-rmse:0.00235\n",
      "[23]\tvalidation_0-rmse:0.00232\n",
      "[24]\tvalidation_0-rmse:0.00229\n",
      "[25]\tvalidation_0-rmse:0.00228\n",
      "[26]\tvalidation_0-rmse:0.00226\n",
      "[27]\tvalidation_0-rmse:0.00224\n",
      "[28]\tvalidation_0-rmse:0.00224\n",
      "[29]\tvalidation_0-rmse:0.00223\n",
      "[30]\tvalidation_0-rmse:0.00223\n",
      "[31]\tvalidation_0-rmse:0.00223\n",
      "[32]\tvalidation_0-rmse:0.00221\n",
      "[33]\tvalidation_0-rmse:0.00221\n",
      "[34]\tvalidation_0-rmse:0.00220\n",
      "[35]\tvalidation_0-rmse:0.00221\n",
      "[36]\tvalidation_0-rmse:0.00221\n",
      "[37]\tvalidation_0-rmse:0.00221\n",
      "[38]\tvalidation_0-rmse:0.00220\n",
      "[39]\tvalidation_0-rmse:0.00220\n",
      "[40]\tvalidation_0-rmse:0.00219\n",
      "[41]\tvalidation_0-rmse:0.00219\n",
      "[42]\tvalidation_0-rmse:0.00219\n",
      "[43]\tvalidation_0-rmse:0.00220\n",
      "[44]\tvalidation_0-rmse:0.00219\n",
      "[45]\tvalidation_0-rmse:0.00219\n",
      "[46]\tvalidation_0-rmse:0.00219\n",
      "[47]\tvalidation_0-rmse:0.00219\n",
      "[48]\tvalidation_0-rmse:0.00219\n",
      "[49]\tvalidation_0-rmse:0.00219\n",
      "[50]\tvalidation_0-rmse:0.00219\n",
      "[51]\tvalidation_0-rmse:0.00218\n",
      "[52]\tvalidation_0-rmse:0.00218\n",
      "[53]\tvalidation_0-rmse:0.00218\n",
      "[54]\tvalidation_0-rmse:0.00218\n",
      "[55]\tvalidation_0-rmse:0.00218\n",
      "[56]\tvalidation_0-rmse:0.00218\n",
      "[57]\tvalidation_0-rmse:0.00218\n",
      "[58]\tvalidation_0-rmse:0.00217\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBRegressor(device = 'cuda',\n",
    "                             objective=\"reg:squarederror\",\n",
    "                             learning_rate = best_params['learning_rate'],\n",
    "                             n_estimators = best_params['n_estimators'],\n",
    "                             max_depth = best_params['max_depth'],\n",
    "                             max_leaves = best_params['max_leaves'],\n",
    "                             subsample = best_params['subsample'],\n",
    "                            )\n",
    "xgb_model.fit(X_train_cp, y_train_cp, eval_set=[(X_test_cp, y_test_cp)])\n",
    "y_pred_np = xgb_model.predict(X_test_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "baefbc8e-2a22-4462-871e-e90c3d72cfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0021736675 4.724831e-06\n"
     ]
    }
   ],
   "source": [
    "mse=mean_squared_error(y_test_cp.get(), y_pred_np)\n",
    "print(np.sqrt(mse),mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dd222fa6-2e0e-488f-bd6e-f2b4a11d3eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_raw = dp.numeric_target_normalizer.inverse_transform(y_test_cp.get().reshape(-1, 1))\n",
    "y_pred_raw = dp.numeric_target_normalizer.inverse_transform(y_pred_np.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3414e284-01c5-488d-b4aa-7c591cca9cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78252.02\n"
     ]
    }
   ],
   "source": [
    "mse=mean_squared_error(y_test_raw, y_pred_raw)\n",
    "print(np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "24c72e79-719e-4569-9a14-1aec99f210ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_vals = xgb_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a80e6fd-e52a-4490-a062-09b73d776a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = xgb_model.feature_names_in_\n",
    "df_from_arr = pd.DataFrame(data=[feature_names,feature_vals]).T\n",
    "df_from_arr.sort_values(by=1,ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f63ed356-610c-45f5-9a2a-8409e82592b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.01780892, 0.01780892, 0., 0.00067523, 0.10227829, 0.00086602, 0., 0.04165217, 3.3471074e-06, 1889, False, False, True, False, False, 0., 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0.03634453, 0.9094314, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, 0, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, 0, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, 0, False, True, 0, False, False, False, True, 0, False, False, 0, False, False, False, True, False, False, False, False, 1, False, False, False, False, 0, False, False, True, False, False, False, 0, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, 0, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, 0, False, 0, False, False, False, False, False, False, False, False, False, 0, False, False, False, False, False, False, 0, False, False, False, False, False, False, False, 0, False, True, 0, False, False, 0, False, False, False, 0, True, False, False, False, False, False, False, 0, True, 0, True, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, 0, False, True, True, False, False, 0, False, False, 0, False, 0, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, 1, False, 0, False, False, False, False, False, False, False, False, False, False, False, False, 0, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, 0, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, True, False, False, 0, False, 0, False, 0, True, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, 0, False, 0, False, True, False, False, False, False, False, False, False, False, True, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, 0, False, False, False, False, False, 0, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, True, False, False, False, False, True, False, False, False, False, False, False, True, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, True, False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.to_records(index=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076097d5-c317-409a-bd94-babb6d6e3ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "aafc9715-c22b-4716-a7b7-1c37bd45b9c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.0093422\ttotal: 2.69s\tremaining: 4m 26s\n",
      "1:\tlearn: 0.0092625\ttotal: 4.82s\tremaining: 3m 56s\n",
      "2:\tlearn: 0.0091860\ttotal: 7.08s\tremaining: 3m 49s\n",
      "3:\tlearn: 0.0091071\ttotal: 9.36s\tremaining: 3m 44s\n",
      "4:\tlearn: 0.0090297\ttotal: 12.1s\tremaining: 3m 49s\n",
      "5:\tlearn: 0.0089529\ttotal: 14.9s\tremaining: 3m 52s\n",
      "6:\tlearn: 0.0088756\ttotal: 17.8s\tremaining: 3m 56s\n",
      "7:\tlearn: 0.0087993\ttotal: 20.3s\tremaining: 3m 53s\n",
      "8:\tlearn: 0.0087249\ttotal: 20.8s\tremaining: 3m 30s\n",
      "9:\tlearn: 0.0086506\ttotal: 23.2s\tremaining: 3m 28s\n",
      "10:\tlearn: 0.0085784\ttotal: 26s\tremaining: 3m 30s\n",
      "11:\tlearn: 0.0085064\ttotal: 28.8s\tremaining: 3m 30s\n",
      "12:\tlearn: 0.0084345\ttotal: 31.9s\tremaining: 3m 33s\n",
      "13:\tlearn: 0.0083635\ttotal: 34.8s\tremaining: 3m 34s\n",
      "14:\tlearn: 0.0082933\ttotal: 37.5s\tremaining: 3m 32s\n",
      "15:\tlearn: 0.0082241\ttotal: 40.1s\tremaining: 3m 30s\n",
      "16:\tlearn: 0.0081551\ttotal: 42.7s\tremaining: 3m 28s\n",
      "17:\tlearn: 0.0080874\ttotal: 45.3s\tremaining: 3m 26s\n",
      "18:\tlearn: 0.0080198\ttotal: 47.8s\tremaining: 3m 23s\n",
      "19:\tlearn: 0.0079544\ttotal: 50.6s\tremaining: 3m 22s\n",
      "20:\tlearn: 0.0078882\ttotal: 53.3s\tremaining: 3m 20s\n",
      "21:\tlearn: 0.0078244\ttotal: 55.8s\tremaining: 3m 17s\n",
      "22:\tlearn: 0.0077606\ttotal: 58.4s\tremaining: 3m 15s\n",
      "23:\tlearn: 0.0076976\ttotal: 1m\tremaining: 3m 12s\n",
      "24:\tlearn: 0.0076344\ttotal: 1m 3s\tremaining: 3m 10s\n",
      "25:\tlearn: 0.0075714\ttotal: 1m 5s\tremaining: 3m 7s\n",
      "26:\tlearn: 0.0075103\ttotal: 1m 8s\tremaining: 3m 5s\n",
      "27:\tlearn: 0.0074489\ttotal: 1m 10s\tremaining: 3m 2s\n",
      "28:\tlearn: 0.0073878\ttotal: 1m 13s\tremaining: 3m\n",
      "29:\tlearn: 0.0073285\ttotal: 1m 16s\tremaining: 2m 57s\n",
      "30:\tlearn: 0.0072689\ttotal: 1m 18s\tremaining: 2m 55s\n",
      "31:\tlearn: 0.0072108\ttotal: 1m 21s\tremaining: 2m 52s\n",
      "32:\tlearn: 0.0071528\ttotal: 1m 23s\tremaining: 2m 49s\n",
      "33:\tlearn: 0.0070948\ttotal: 1m 26s\tremaining: 2m 47s\n",
      "34:\tlearn: 0.0070394\ttotal: 1m 29s\tremaining: 2m 45s\n",
      "35:\tlearn: 0.0069830\ttotal: 1m 31s\tremaining: 2m 43s\n",
      "36:\tlearn: 0.0069267\ttotal: 1m 34s\tremaining: 2m 41s\n",
      "37:\tlearn: 0.0068723\ttotal: 1m 37s\tremaining: 2m 38s\n",
      "38:\tlearn: 0.0068189\ttotal: 1m 39s\tremaining: 2m 36s\n",
      "39:\tlearn: 0.0067647\ttotal: 1m 42s\tremaining: 2m 33s\n",
      "40:\tlearn: 0.0067111\ttotal: 1m 44s\tremaining: 2m 30s\n",
      "41:\tlearn: 0.0066578\ttotal: 1m 47s\tremaining: 2m 28s\n",
      "42:\tlearn: 0.0066050\ttotal: 1m 50s\tremaining: 2m 26s\n",
      "43:\tlearn: 0.0065534\ttotal: 1m 53s\tremaining: 2m 24s\n",
      "44:\tlearn: 0.0065025\ttotal: 1m 55s\tremaining: 2m 21s\n",
      "45:\tlearn: 0.0064517\ttotal: 1m 58s\tremaining: 2m 19s\n",
      "46:\tlearn: 0.0064025\ttotal: 2m 1s\tremaining: 2m 16s\n",
      "47:\tlearn: 0.0063524\ttotal: 2m 3s\tremaining: 2m 14s\n",
      "48:\tlearn: 0.0063040\ttotal: 2m 6s\tremaining: 2m 11s\n",
      "49:\tlearn: 0.0062556\ttotal: 2m 9s\tremaining: 2m 9s\n",
      "50:\tlearn: 0.0062077\ttotal: 2m 12s\tremaining: 2m 7s\n",
      "51:\tlearn: 0.0061603\ttotal: 2m 15s\tremaining: 2m 4s\n",
      "52:\tlearn: 0.0061148\ttotal: 2m 17s\tremaining: 2m 2s\n",
      "53:\tlearn: 0.0060686\ttotal: 2m 20s\tremaining: 1m 59s\n",
      "54:\tlearn: 0.0060221\ttotal: 2m 22s\tremaining: 1m 56s\n",
      "55:\tlearn: 0.0059763\ttotal: 2m 25s\tremaining: 1m 54s\n",
      "56:\tlearn: 0.0059319\ttotal: 2m 28s\tremaining: 1m 52s\n",
      "57:\tlearn: 0.0058874\ttotal: 2m 31s\tremaining: 1m 49s\n",
      "58:\tlearn: 0.0058433\ttotal: 2m 34s\tremaining: 1m 47s\n",
      "59:\tlearn: 0.0058003\ttotal: 2m 36s\tremaining: 1m 44s\n",
      "60:\tlearn: 0.0057570\ttotal: 2m 39s\tremaining: 1m 41s\n",
      "61:\tlearn: 0.0057145\ttotal: 2m 42s\tremaining: 1m 39s\n",
      "62:\tlearn: 0.0056724\ttotal: 2m 44s\tremaining: 1m 36s\n",
      "63:\tlearn: 0.0056302\ttotal: 2m 47s\tremaining: 1m 33s\n",
      "64:\tlearn: 0.0055894\ttotal: 2m 49s\tremaining: 1m 31s\n",
      "65:\tlearn: 0.0055476\ttotal: 2m 52s\tremaining: 1m 28s\n",
      "66:\tlearn: 0.0055069\ttotal: 2m 54s\tremaining: 1m 26s\n",
      "67:\tlearn: 0.0054665\ttotal: 2m 57s\tremaining: 1m 23s\n",
      "68:\tlearn: 0.0054277\ttotal: 3m\tremaining: 1m 20s\n",
      "69:\tlearn: 0.0053884\ttotal: 3m 3s\tremaining: 1m 18s\n",
      "70:\tlearn: 0.0053500\ttotal: 3m 5s\tremaining: 1m 15s\n",
      "71:\tlearn: 0.0053121\ttotal: 3m 8s\tremaining: 1m 13s\n",
      "72:\tlearn: 0.0052748\ttotal: 3m 8s\tremaining: 1m 9s\n",
      "73:\tlearn: 0.0052376\ttotal: 3m 10s\tremaining: 1m 7s\n",
      "74:\tlearn: 0.0052003\ttotal: 3m 13s\tremaining: 1m 4s\n",
      "75:\tlearn: 0.0051641\ttotal: 3m 15s\tremaining: 1m 1s\n",
      "76:\tlearn: 0.0051277\ttotal: 3m 17s\tremaining: 59.1s\n",
      "77:\tlearn: 0.0050911\ttotal: 3m 20s\tremaining: 56.5s\n",
      "78:\tlearn: 0.0050562\ttotal: 3m 22s\tremaining: 53.9s\n",
      "79:\tlearn: 0.0050210\ttotal: 3m 25s\tremaining: 51.4s\n",
      "80:\tlearn: 0.0049860\ttotal: 3m 28s\tremaining: 48.9s\n",
      "81:\tlearn: 0.0049520\ttotal: 3m 31s\tremaining: 46.4s\n",
      "82:\tlearn: 0.0049174\ttotal: 3m 34s\tremaining: 43.8s\n",
      "83:\tlearn: 0.0048835\ttotal: 3m 36s\tremaining: 41.3s\n",
      "84:\tlearn: 0.0048506\ttotal: 3m 39s\tremaining: 38.7s\n",
      "85:\tlearn: 0.0048182\ttotal: 3m 41s\tremaining: 36.1s\n",
      "86:\tlearn: 0.0047852\ttotal: 3m 44s\tremaining: 33.5s\n",
      "87:\tlearn: 0.0047533\ttotal: 3m 46s\tremaining: 30.9s\n",
      "88:\tlearn: 0.0047212\ttotal: 3m 49s\tremaining: 28.3s\n",
      "89:\tlearn: 0.0046890\ttotal: 3m 51s\tremaining: 25.8s\n",
      "90:\tlearn: 0.0046582\ttotal: 3m 54s\tremaining: 23.2s\n",
      "91:\tlearn: 0.0046272\ttotal: 3m 56s\tremaining: 20.6s\n",
      "92:\tlearn: 0.0045960\ttotal: 3m 59s\tremaining: 18s\n",
      "93:\tlearn: 0.0045659\ttotal: 4m 1s\tremaining: 15.4s\n",
      "94:\tlearn: 0.0045365\ttotal: 4m 4s\tremaining: 12.9s\n",
      "95:\tlearn: 0.0045068\ttotal: 4m 7s\tremaining: 10.3s\n",
      "96:\tlearn: 0.0044774\ttotal: 4m 10s\tremaining: 7.73s\n",
      "97:\tlearn: 0.0044485\ttotal: 4m 12s\tremaining: 5.15s\n",
      "98:\tlearn: 0.0044197\ttotal: 4m 14s\tremaining: 2.58s\n",
      "99:\tlearn: 0.0043914\ttotal: 4m 17s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "# initialize data\n",
    "train_data = X_train\n",
    "train_label = y_train\n",
    "test_data = X_train\n",
    "# initialize Pool\n",
    "train_pool = Pool(train_data, \n",
    "                  train_label)\n",
    "test_pool = Pool(test_data) \n",
    "\n",
    "# specify the training parameters \n",
    "model = CatBoostRegressor(iterations=100, \n",
    "                          depth=15, \n",
    "                          learning_rate=.01, \n",
    "                          loss_function='RMSE')\n",
    "#train the model\n",
    "model.fit(train_pool)\n",
    "# make the prediction using the resulting model\n",
    "preds = model.predict(test_pool)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
